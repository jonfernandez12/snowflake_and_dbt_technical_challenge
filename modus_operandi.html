
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="statement.html">
      
      
        <link rel="next" href="faced_problems.html">
      
      
      <link rel="icon" href="img/caspar_health_icon.jpg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Modus operandi - Caspar Health Technical Challenge</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#modus-operandi" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="." title="Caspar Health Technical Challenge" class="md-header__button md-logo" aria-label="Caspar Health Technical Challenge" data-md-component="logo">
      
  <img src="img/caspar_health_icon.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Caspar Health Technical Challenge
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Modus operandi
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="." title="Caspar Health Technical Challenge" class="md-nav__button md-logo" aria-label="Caspar Health Technical Challenge" data-md-component="logo">
      
  <img src="img/caspar_health_icon.jpg" alt="logo">

    </a>
    Caspar Health Technical Challenge
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="statement.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statement
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="modus_operandi.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Modus operandi
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="faced_problems.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Faced problems
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="future_implementations.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Future implementations
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="tests/index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tests Report
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="modus-operandi">Modus Operandi</h1>
<p>The following document aims to gather all the steps I thought about during 
the development of the technical challenge.</p>
<h1 id="landing-the-challenge">Landing the challenge</h1>
<p>First, I read the challenge several times to makes sure I understood the task. 
At first glance, it does not seem a very complex task, also the datasets are 
not very big so I suppose I will not have any issues processing the data.</p>
<p>The final output is based on the join of patients with steps and exercises 
accordingly and calculating the maximum sum of minutes (coming from steps and 
exercises) grouped by patient.</p>
<h1 id="infrastructure-discussion">Infrastructure discussion</h1>
<p>Since I am familiar with Airflow and dbt (I did no use it in 2 years so lets
see what changed) and the challenge itself does not seem extremely 
complex I would love to invest some time in creating a proper infrastructure:
 - Dockerized Airflow and DBT with connection to Snowflake</p>
<p>However, I have never deployed Airflow locally from scratch (everywhere I went,
it was already there) so I will leave deploying dbt in Airflow for the end.</p>
<p>I decided to use Snowflake as database based on:
- I did not use it before and I want to learn a new DB engine.
- It was listed in the nice-to-have list of the job offer.</p>
<p>Also, I would like to implement data QA tests (table constraints, business
criteria and schema checks), a CI/CD pipeline to automate python tests, add
renovate bot to the repository and documentation deployment to the git project
,but we will see how it goes.</p>
<p>Not sure if I will create a dashboard for the results, but it would be nice as 
well. I have some ideas for other KPIs:
- Apart from <code>total_minutes</code>, we can show as well the minutes coming from 
steps and the ones coming from exercises, it could be a useful KPI to get more
insights about the rehabilitation.
- We can also split the maximum total minutes per country and, as in the 
previous point, split it in exercises and steps.
- Steps and exercises submission_time(s) graphs (respectively) , it would be
great to know when (along the year) are usually the patients doing more steps
and exercises, maybe it has some effect on their rehabilitation time.</p>
<h1 id="setting-up-github">Setting up Github</h1>
<p>I am not sure if it is relevant but as I am using a laptop with an already
paired Gitlab account, I had to create another SSH key and assign this new SSH 
key to the Github account I am going to use for the challenge:</p>
<div class="highlight"><pre><span></span><code>ssh-keygen<span class="w"> </span>-t<span class="w"> </span>ed25519<span class="w"> </span>-C<span class="w"> </span><span class="s2">&quot;my@mail.com&quot;</span>
ssh-add<span class="w"> </span>--apple-use-keychain<span class="w"> </span>~/.ssh/my_id<span class="w"> </span>
nano<span class="w"> </span>/Users/jonfernandez/.ssh/config
</code></pre></div>
<p>And here add:</p>
<p><div class="highlight"><pre><span></span><code>  Host *
    UseKeychain yes
    AddKeysToAgent yes
    IdentityFile ~/.ssh/my_id
</code></pre></div>
In Github SSH configuration section add the content of <code>cat ~/.ssh/my_id.pub</code>
as always. Finally, and I think this changed recently, I had to log in with
github-cli <code>gh auth login</code>.</p>
<h1 id="setting-up-snowflake">Setting up Snowflake</h1>
<p>I am starting by setting up the Snowflake user for dbt as recommended in
<a href="https://quickstarts.snowflake.com/guide/data_engineering_with_apache_airflow/index.html#0">one of the Snowflake's quickstart guides.</a></p>
<div class="highlight"><pre><span></span><code>USE ROLE SECURITYADMIN;

-- We create the role that DBT user will use: dbt_developer_role 
CREATE OR REPLACE ROLE dbt_developer_role COMMENT=&#39;DBT developer role&#39;;
GRANT ROLE dbt_developer_role TO ROLE SYSADMIN;

-- Create the DBT user
CREATE OR REPLACE USER dbt_user PASSWORD=&#39;dbt_password&#39;
    DEFAULT_ROLE=dbt_developer_role
    DEFAULT_WAREHOUSE=dbt_warehouse
    COMMENT=&#39;DBT User&#39;;

GRANT ROLE dbt_developer_role TO USER dbt_user;

-- To grant privileges to the role we need to use a role with higher permissions 
USE ROLE ACCOUNTADMIN;

GRANT CREATE DATABASE ON ACCOUNT TO ROLE dbt_developer_role;

USE ROLE SYSADMIN;

-- Create Warehouse for DBT
CREATE OR REPLACE WAREHOUSE dbt_developer_warehouse
  WITH WAREHOUSE_SIZE = &#39;XSMALL&#39;
  AUTO_SUSPEND = 120
  AUTO_RESUME = true
  INITIALLY_SUSPENDED = TRUE;

GRANT ALL ON WAREHOUSE dbt_developer_warehouse TO ROLE dbt_developer_role;
</code></pre></div>
<h2 id="early-data-model-approach">Early data model approach</h2>
<p>After that, we create the data model for our patients, exercises and steps.
The assumptions and standards I chose to follow:</p>
<ul>
<li>We prefer plural from singular table namings so as SQL code is more
intuitive: <code>SELECT * FROM patients;</code></li>
<li>We prefer explicit over implicit type definition (i.e. we use<code>NUMBER(38,0)</code>
instead of <code>INTEGER</code> so the amount of decimals is properly defined in the code
even though <code>NUMBER(38,0)</code> is the <a href="https://docs.snowflake.com/en/sql-reference/data-types-numeric#number">standard in Snowflake for numeric data 
types</a>)</li>
<li>Same goes for string data types, we will be using <code>VARCHAR(16777216)</code> which
would be the same as using <code>VARCHAR</code> but we rather define the maximum length
of the field in our code.</li>
<li>It would be great to align with the team in charge of building the source of
the data so as we can define properly the limits of the values in the columns 
and use it as a second type validation.</li>
<li>In exercises and steps tables, <code>external_id</code> column names will be modified
to <code>patient_id</code>.</li>
<li>For the timestamp columns, I used <a href="https://docs.snowflake.com/en/sql-reference/data-types-datetime#timestamp-ltz-timestamp-ntz-timestamp-tz">TIMESTAMP_TZ</a> Snowflake type since,
in the data, it looks like the UTC offset is defined after the timestamp 
(i.e. <code>2024-04-11T14:25:23.708+0200</code>). However, we will need to take into 
account that <code>Attention</code> section defined in the documentation when using this
field for creating KPIs, since the offset of some countries change during the 
year but not the value of the field. If possible I would ask the team in charge 
of creating the source data to send us the values of the TIMEZONE together with
the timestamp (without the UTC offset in this case) so as we can calculate 
the UTC time in place when needed.</li>
<li>In steps tables, <code>submission_time</code> column name will be modified 
to <code>submitted_at</code>, like that all the columns with type <code>TIMESTAMP_TZ</code> will have
the same suffix and we will be able to identify the type of the column by its 
name.</li>
<li>When trying to test how Snowflake is reading the timestamp values from the 
spreadsheet <code>SELECT '2023-04-19T19:03:58.0520200'::TIMESTAMP_TZ</code> I got
<code>Timestamp '2023-08-04T21:26:24.871+0200' is not recognized</code> so I tried:</li>
</ul>
<div class="highlight"><pre><span></span><code>ALTER SESSION SET TIMESTAMP_TZ_OUTPUT_FORMAT = &#39;YYYY-MM-DDTHH24:MI:SS.FF3TZHTZM&#39;;
</code></pre></div>
<p>It looks like it can read it know, we will take care of this when importing the
data to Snowflake. </p>
<p>The table creation script I used for the staging tables is the following:
<div class="highlight"><pre><span></span><code>CREATE OR REPLACE DATABASE caspar_health;
USE ROLE dbt_developer_role;

CREATE TABLE stg_patients (
    row_id  NUMBER(38, 0),
    patient_id NUMBER(38, 0),
    first_name VARCHAR(16777216),
    last_name VARCHAR(16777216),
    country VARCHAR(16777216)
);
CREATE TABLE stg_exercises (
    id NUMBER(38, 0),
    external_id NUMBER(38, 0),
    minutes NUMBER(38, 0),
    completed_at VARCHAR(16777216),
    updated_at VARCHAR(16777216)
);
CREATE TABLE stg_steps (
    id NUMBER(38, 0),
    external_id NUMBER(38, 0),
    steps NUMBER(38, 0),
    submission_time VARCHAR(16777216),
    updated_at VARCHAR(16777216)
);

ALTER SESSION SET TIMESTAMP_TZ_OUTPUT_FORMAT = &#39;YYYY-MM-DDTHH24:MI:SS.FF3TZHTZM&#39;;
</code></pre></div></p>
<h1 id="setting-up-dbt">Setting up DBT</h1>
<h2 id="setting-up-the-python-environment">Setting up the Python environment</h2>
<p>I am going to be using <a href="https://github.com/astral-sh/uv">uv</a> as a python 
package manager to start with the dbt dependencies. It is being a while since 
I wanted to try uv out, is supposed to be very fast.</p>
<div class="highlight"><pre><span></span><code>brew install uv
uv init caspar_health_technical_challenge
uv add dbt-core
uv add dbt-snowflake
</code></pre></div>
<p>*<em>Yes, it was fast indeed.</em></p>
<p>I am not using <code>dbt-cloud</code> since looks expensive for what it offers and it is 
not really complicated to set up and deploy <code>dbt-core</code> but maybe I regret it. 
I run <code>dbt init</code> to create the dbt project. Then, <code>dbt deps</code> to install the 
dependencies (<code>dbt-labs/dbt_utils</code>). The dbt profile would look as follows:</p>
<div class="highlight"><pre><span></span><code>caspar_health_technical_challenge:
<span class="w">  </span>outputs:
<span class="w">    </span>dev:
<span class="w">      </span>account:<span class="w"> </span>RG94457.EU-CENTRAL-1
<span class="w">      </span>database:<span class="w"> </span>CASPAR_HEALTH
<span class="w">      </span>password:<span class="w"> </span>dbt_password
<span class="w">      </span>role:<span class="w"> </span>dbt_developer_role
<span class="w">      </span>schema:<span class="w"> </span>rehabilitation_data
<span class="w">      </span>threads:<span class="w"> </span><span class="m">1</span>
<span class="w">      </span>type:<span class="w"> </span>snowflake
<span class="w">      </span>user:<span class="w"> </span>dbt_user
<span class="w">      </span>warehouse:<span class="w"> </span>dbt_developer_warehouse
<span class="w">  </span>target:<span class="w"> </span>dev
</code></pre></div>
<p>It took me some time to figure the Snowflake connection parameters out to 
create the dbt profile, more specifically;
- <strong>account</strong>: I had to run a query on Snowflake to get it.
<div class="highlight"><pre><span></span><code>SELECT CONCAT_WS(&#39;.&#39;, CURRENT_ACCOUNT(), REPLACE(REGEXP_REPLACE(CURRENT_REGION(), &#39;^[^_]+_&#39;,&#39;&#39;), &#39;_&#39;, &#39;-&#39;)); -- e.g.: `YY00042.EU-CENTRAL-1`
</code></pre></div>
- <strong>password and user</strong>: I did not know if it was the Snowflake account or the 
database specific account.</p>
<p>I added a <code>generate_schema_name</code> and <code>set_query_tag</code> macros as recommended 
in the <a href="[documentation](https://quickstarts.snowflake.com/guide/data_engineering_with_apache_airflow/index.html#0)">Snowflake quickstart guide</a> I am following.</p>
<h2 id="loading-raw-data">Loading raw data</h2>
<p>After setting up dbt, I decided to try to import the raw data into Snowflake.
I added the CSV files into the <code>seeds</code> folder and tried to run <code>dbt seed</code>
but I got the following error:</p>
<div class="highlight"><pre><span></span><code>Runtime<span class="w"> </span>Error
<span class="w">  </span>Database<span class="w"> </span>error<span class="w"> </span><span class="k">while</span><span class="w"> </span>listing<span class="w"> </span>schemas<span class="w"> </span><span class="k">in</span><span class="w"> </span>database<span class="w"> </span><span class="s2">&quot;CASPAR_HEALTH&quot;</span>
<span class="w">  </span>Database<span class="w"> </span>Error
<span class="w">    </span><span class="m">002043</span><span class="w"> </span><span class="o">(</span><span class="m">02000</span><span class="o">)</span>:<span class="w"> </span>SQL<span class="w"> </span>compilation<span class="w"> </span>error:
<span class="w">    </span>Object<span class="w"> </span>does<span class="w"> </span>not<span class="w"> </span>exist,<span class="w"> </span>or<span class="w"> </span>operation<span class="w"> </span>cannot<span class="w"> </span>be<span class="w"> </span>performed.
</code></pre></div>
<p>And since I could not see the query, I went to the logs, and apparently I was 
trying to run <code>show objects in CASPAR_HEALTH.rehabilitation_data limit 10000</code>
but, of course, <code>rehabilitation_data</code> schema does not exist, it should 
be <code>public</code> instead. For some reason, I thought that DBT was creating a 
new schema when adding data from seeds.</p>
<p>I took the decision of adding the <code>stg</code> suffix to the tables names containing 
raw data as specified in dbt documentation. I learned that, <a href="https://www.y42.com/learn/dbt/dbt-seed#overview-of-dbt-seeds">according to this 
post,</a>
apparently <code>dbt seeds</code> is not the greatest option to bulk raw data into 
Snowflake and, honestly, I would rather define a dbt model with
<a href="https://docs.snowflake.com/en/user-guide/data-load-s3-copy">COPY INTO table</a> clause, but I do not have any personal cloud storage 
account so I am going with dbt seeds for this very specific challenge.</p>
<p>The data bulk worked with no issue for <code>steps</code> and <code>exercices</code>, however, for 
<code>patients</code>, I had to use <code>--full-refresh</code> option (only for the very first time 
we bulk the data) since the 1st column name is empty. Due to that, the 1st 
column name for this table will have <code>A</code> as a column name instead of <code>row_id</code> 
as planned. We could have avoided this by loading the data directly from a 
cloud storage and just not selecting that column. I am not planning on using
the column anyway in further tables, so it should not be an issue.</p>
<h2 id="dimensions-and-facts">Dimensions and facts</h2>
<p>Once our raw data has been loaded, is time to discuss which 
transformations we will be doing to our data.</p>
<p>For this specific case and with no further knowledge about future 
requirements, I would go with a simple dimensions and facts data model design
where Patients will be the main dimension and Steps and Exercises the 
facts that do not make sense without our dimension. The data model design 
has not a big impact in this specific case apart from helping understand our 
data and defining the primary keys (<code>id</code> in <code>patients</code>) and foreign keys 
(<code>patient_id</code> in <code>steps</code> and <code>exercises</code>). </p>
<p>This tables will be kept in <code>transform</code> schema (as defined in the
<a href="https://quickstarts.snowflake.com/guide/data_engineering_with_apache_airflow/index.html#0">Snowflake guide we are following</a>) since they are part of the base layer of our model, and 
they all should have a <code>seed</code> or raw data as source. In this state
we will be taking care of the transformations mentioned in section
<a href="#early-data-model-approach">Early data model approach</a> and automatic dbt 
data QA tests defined on the table constraints such as:
    - primary keys (unique, not null)
    - foreign keys (referenced to the origin)
    - type validation</p>
<p>I added <code>not null</code> constraint to almost every field in the data model because 
the data shows that it is possible, however, it would be great to confirm 
and truly redefine which columns expect <code>null</code> values and which do not.</p>
<p>Since we do not have any constraint in one model that applies to multiple 
columns, we will be only defining <code>column-level</code> constraints and not 
<code>model-level</code> constraints. Also, we are going to use one file per model to 
define the schema instead of defining all the schemas in the same file so 
the code structure scales up in a clean and organized way.</p>
<h2 id="analysis-tables">Analysis tables</h2>
<p>Finally, we are building two analysis tables and we will be using <code>analysis</code>
schema for that.</p>
<p>First, we will join patients data with steps and exercises data so as we can
group it and sum it. We will also be creating the KPI <code>total_minutes</code>, a sum of
the minutes coming from steps and exercises, so as we can get the maximum 
value(s) in the last results table. And last but not list, we will create a 
column with a <code>RANK()</code> window function ordered by <code>total_minutes</code> descendant, 
which will return the same value in case the maximum value is repeated for 
different patients.</p>
<p>Second, we will obtain our aimed KPI filtering the rank field we created in the 
previous table with <code>1</code>. </p>
<div class="highlight"><pre><span></span><code>SELECT *
FROM caspar_health.analysis.results_patients;
</code></pre></div>
<table>
<thead>
<tr>
<th>patient_id:int</th>
<th>first_name:str</th>
<th>last_name:str</th>
<th>country:str</th>
<th>total_minutes:number(38,3)</th>
</tr>
</thead>
<tbody>
<tr>
<td>356134</td>
<td>Austin</td>
<td>Ellis</td>
<td>Germany</td>
<td>54954235.000</td>
</tr>
</tbody>
</table>
<p>*_<code>total_minutes</code> column is decimal type (and it was proposed to be <code>int</code> 
 type) since one of the columns involved in the KPI had 3 decimals as well.</p>
<p>I would love to create more KPIs as defined in <a href="#infrastructure-discussion">Infrastructure discussion</a> 
section, but I am going to focus on deploying dbt in Airflow, adding 
python pytest tests, sqlfluff, ruff and proper documentation first.</p>
<h1 id="setting-up-airflow">Setting up Airflow</h1>
<p>Following the <a href="https://quickstarts.snowflake.com/guide/data_engineering_with_apache_airflow/index.html#5">Snowflake guide</a>
we might need to get rid of uv for setting up python requirements and go with
plain pip requirement management. We will now prepare the repository for 
encapsulating our model creation with dbt inside an airflow repository 
ready to be deployed.</p>
<p>We can create a dockerized airflow repository by creating a new folder and 
running <code>astro dev init</code> (from <a href="https://www.astronomer.io/docs/astro/">astro</a>), after that I will just add all my dbt packages
inside <code>dags/dbt/caspar_health_dbt_cosmos</code> folder.</p>
<h2 id="setting-up-the-dag">Setting up the DAG</h2>
<p>The <code>patient_data_elt</code> DAG is only composed by:
1. Dbt profile definition: Which basically, thanks to a very cool <a href="https://github.com/astronomer/astronomer-cosmos">cosmos</a>
library, reads all the credentials from the predefined Airflow connections in 
<code>airflow_settings.yaml</code>. Given the use case, I am not going to spend more time 
trying to hide the secrets since in a real-life scenario I would just use 
<a href="https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/secrets-backends/aws-secrets-manager.html">Airflow AWS Secrets Manager Backend</a>
for getting the credentials of the connections.
2. Dbt DAG: We create tasks that run every existing model in
DBT, even the seeds creating a <code>DbtDag</code> module.</p>
<p><img alt="img.png" src="img/successfully_running_dag.png" /></p>
<h2 id="astro-and-cosmos">Astro and cosmos</h2>
<p>I did not use <code>astro</code> and <code>cosmos</code> until today and is crazy how easy they make:
- <strong>Astro</strong>: It deploys the webserver, the scheduler and the trigger 
(I guess this is the Celery queue). I just did not need to think about it, 
which is nice for this use case. However, I can imagine that those layers of 
abstraction that adds on top of Airflow might be a bit cumbersome when we want
to adjust Airflow to some specific needs. Also, it took me quite some time to
discover how to deploy the connections defined on <code>airflow_settings.yaml</code>: 
<div class="highlight"><pre><span></span><code>astro dev object import
astro dev restart
</code></pre></div></p>
<ul>
<li><strong>Cosmos</strong>: I really do not have any complains about it for now but again, it 
could be not the best option if we want to really get the most out of dbt.</li>
</ul>
<h1 id="setting-up-tests-tndd">Setting up tests (TNDD)</h1>
<p>Well, I would have loved to apply TDD during the development of these tasks, 
however, I got excited by the use of uv at the beginning and I forgot about it.
That is why we will can call it Test Non Driven Development in this case.</p>
<p>I did not add any python tests myself since I did not see the case for it, 
maybe it would have been great to:
- Test somehow the connection with Snowflake (with a given dbt profile)
- Test the output of the dbt models somehow.</p>
<p>What I did add is sqlfluff and ruff, which are very nice SQL and python linters
that help so much following predefined code standards.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>